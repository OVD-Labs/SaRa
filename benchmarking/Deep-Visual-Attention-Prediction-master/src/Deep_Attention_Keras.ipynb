{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Attention_Keras.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1EURAoelzNTbdpSCCLHHzAC3eZrFaovOj",
          "timestamp": 1525544589777
        },
        {
          "file_id": "1_e7NbJ8WSGW4chf_XVdy1MihNgTUp9yg",
          "timestamp": 1525492272238
        }
      ],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Repg9Qqbcwem",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/s/ttc9hmcca04lc02/sal_data.zip?dl=0\n",
        "!mv sal_data.zip?dl=0 sal_data.zip\n",
        "!unzip sal_data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NJqP6CLJc8US",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/s/0yluib4kmbhi9f4/sal_train_val.zip?dl=0\n",
        "!mv sal_train_val.zip?dl=0 sal_train_val.zip\n",
        "!unzip sal_train_val.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "naeQe-l3buEX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install pydot\n",
        "!pip install pyemd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dDVgHPURBU-A",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JIaWWj-weHDN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import Input, Dense, Lambda, Flatten, Reshape, Concatenate,Activation\n",
        "from keras.layers import concatenate\n",
        "from keras.layers import Conv2D, Conv2DTranspose, ZeroPadding2D,MaxPooling2D, Cropping2D, BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras import metrics\n",
        "from keras import backend as K\n",
        "from keras import optimizers\n",
        "from keras import losses\n",
        "from keras.utils import plot_model\n",
        "from keras.callbacks import Callback\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "import skimage.io as io\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pydot\n",
        "from pyemd import emd, emd_samples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8wRrmah6BRTf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "K.set_floatx('float32')\n",
        "emd_arr = []\n",
        "lcc_arr = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1eL3jbehHPLo",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class TestCallback(Callback):\n",
        "    def __init__(self, X_train, Y_train, model):\n",
        "      self.X_train = X_train\n",
        "      self.Y_train = np.array(Y_train)\n",
        "      self.model = model\n",
        "\n",
        "      \n",
        "    #'Called at the end of the epoch'     \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        global emd_arr, lcc_arr\n",
        "        [y_p, y_t] = self.get_y(20)\n",
        "        emd_val = self.get_emd(y_p, y_t)\n",
        "        lcc_val = self.get_lcc(y_p, y_t)\n",
        "        print('EMD', emd_val)\n",
        "        print('LCC', lcc_val)\n",
        "        emd_arr.append(emd_val)\n",
        "        lcc_arr.append(lcc_val)\n",
        "      \n",
        "      \n",
        "    #'Returns the prediction and the true value in numpy array format'    \n",
        "    def get_y(self, index):\n",
        "        y_pred = self.model.predict(self.X_train)\n",
        "        y_pred = np.array(y_pred[3])\n",
        "        y_true = np.array(self.Y_train)\n",
        "        y_p = y_pred[index,:,:,0]\n",
        "        y_t = y_true[index,:,:,0]\n",
        "        y_p = np.ravel(y_p)\n",
        "        y_t = np.ravel(y_t)\n",
        "        return [y_p, y_t]\n",
        "      \n",
        "      \n",
        "    #'Returns the Earth Movers Distance between prediction and truth'\n",
        "    def get_emd(self,y_pred, y_true):\n",
        "      return emd_samples(y_pred, y_true)\n",
        "    \n",
        "    \n",
        "    #'Returns the Linear Correlation Coefficient between prediction and truth '\n",
        "    def get_lcc(self,y_pred, y_true):\n",
        "      return np.corrcoef(y_pred, y_true)[0,1]\n",
        "    \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V-T1aLJleLhY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class AttentionModel:\n",
        "  def __init__(self):\n",
        "        self.batch_size = 16\n",
        "        self.epochs = 2 #10\n",
        "        self.lr = 0.0001\n",
        "        self.train_no_images = 100#0\n",
        "        self.test_no_images = 10#0\n",
        "        \n",
        "        \n",
        "  #'Returns Data arrays with given number of samples'      \n",
        "  def dataLoadBatch(self, num_samples):\n",
        "        X=[]\n",
        "        Y=[]\n",
        "        for h in range(0, num_samples):\n",
        "            I = io.imread(\"data/images/salMap_{:05d}.jpg\".format(h))\n",
        "            X.append(I)\n",
        "            bin_label = np.zeros((224,224))\n",
        "            labels = io.imread(\"data/salMap/salMap_{:05d}.jpg\".format(h))[:,:,0]\n",
        "            for i in range(0,224):\n",
        "                for j in range(0,224):\n",
        "                  if labels[i][j]<26:\n",
        "                      bin_label[i][j] = 0\n",
        "                  elif labels[i][j]<51:\n",
        "                      bin_label[i][j] = 0.111\n",
        "                  elif labels[i][j]<76:\n",
        "                      bin_label[i][j] = 0.222\n",
        "                  elif labels[i][j]<102:\n",
        "                      bin_label[i][j] = 0.333\n",
        "                  elif labels[i][j]<128:\n",
        "                      bin_label[i][j] = 0.444\n",
        "                  elif labels[i][j]<154:\n",
        "                      bin_label[i][j] = 0.556\n",
        "                  elif labels[i][j]<180:\n",
        "                      bin_label[i][j] = 0.667\n",
        "                  elif labels[i][j]<206:\n",
        "                      bin_label[i][j] = 0.778\n",
        "                  elif labels[i][j]<230:\n",
        "                      bin_label[i][j] = 0.889                  \n",
        "                  else:\n",
        "                      bin_label[i][j] = 1\n",
        "            Y.append(bin_label)\n",
        "        X = np.array(X)\n",
        "        Y = np.array(Y)\n",
        "        \n",
        "        return X,Y\n",
        "        \n",
        "        \n",
        "  #Defines the model architecture      \n",
        "  def DeepAttentionModel(self):\n",
        "    img_rows, img_cols, img_chns = 224, 224, 3\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "      original_img_size = (img_chns, img_rows, img_cols)\n",
        "    else:\n",
        "      original_img_size = (img_rows, img_cols, img_chns)\n",
        "    \n",
        "    \n",
        "    self.x = Input(shape=original_img_size)\n",
        "    padded_x = ZeroPadding2D(padding=(35), data_format=\"channels_last\")(self.x)\n",
        "    \n",
        "    \n",
        "    #'Encoder'\n",
        "    conv_1_1 = Conv2D(64, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu',data_format=\"channels_last\")(padded_x)\n",
        "    padded_conv_1_1 = ZeroPadding2D(padding=(1), data_format=\"channels_last\")(conv_1_1)\n",
        "    conv_1_2 = Conv2D(64, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu',data_format=\"channels_last\")(padded_conv_1_1)\n",
        "    pool_1 = MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=\"channels_last\")(conv_1_2)\n",
        "    \n",
        "    padded_input_pool_1=  ZeroPadding2D(padding=(1), data_format=\"channels_last\")(pool_1)\n",
        "    conv_2_1 = Conv2D(128, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu',data_format=\"channels_last\")(padded_input_pool_1)\n",
        "    padded_input_conv_2_1 = ZeroPadding2D(padding=(1), data_format=\"channels_last\")(conv_2_1)\n",
        "    conv_2_2 = Conv2D(128, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu',data_format=\"channels_last\")(padded_input_conv_2_1)\n",
        "    pool_2 = MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=\"channels_last\")(conv_2_2)\n",
        "    \n",
        "    padded_input_pool_2=  ZeroPadding2D(padding=(1), data_format=None)(pool_2)\n",
        "    conv_3_1 = Conv2D(256, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(padded_input_pool_2)\n",
        "    padded_input_conv_3_1 = ZeroPadding2D(padding=(1), data_format=None)(conv_3_1)\n",
        "    conv_3_2 = Conv2D(256, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(padded_input_conv_3_1)\n",
        "    padded_input_conv_3_2 = ZeroPadding2D(padding=(1), data_format=None)(conv_3_2)\n",
        "    conv_3_3 = Conv2D(256, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(padded_input_conv_3_2)\n",
        "    pool_3 = MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=None)(conv_3_3)\n",
        "    \n",
        "    padded_input_pool_3 =  ZeroPadding2D(padding=(1), data_format=None)(pool_3)\n",
        "    conv_4_1 = Conv2D(512, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(padded_input_pool_3)\n",
        "    padded_input_conv_4_1 = ZeroPadding2D(padding=(1), data_format=None)(conv_4_1)\n",
        "    conv_4_2 = Conv2D(512, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(padded_input_conv_4_1)\n",
        "    padded_input_conv_4_2 = ZeroPadding2D(padding=(1), data_format=None)(conv_4_2)\n",
        "    conv_4_3 = Conv2D(512, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(padded_input_conv_4_2)\n",
        "    pool_4 = MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=None)(conv_4_3)\n",
        "    \n",
        "    padded_input_pool_4 =  ZeroPadding2D(padding=(1), data_format=None)(pool_4)\n",
        "    conv_5_1 = Conv2D(512, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(padded_input_pool_4)\n",
        "    padded_input_conv_5_1 = ZeroPadding2D(padding=(1), data_format=None)(conv_5_1)\n",
        "    conv_5_2 = Conv2D(512, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(padded_input_conv_5_1)\n",
        "    padded_input_conv_5_2 = ZeroPadding2D(padding=(1), data_format=None)(conv_5_2)\n",
        "    conv_5_3 = Conv2D(512, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(padded_input_conv_5_2)\n",
        "    \n",
        "    \n",
        "    #'Decoder'\n",
        "    deconv_5_1 = Conv2DTranspose(512,kernel_size=(4, 4),strides=(2, 2), padding='valid', activation='relu')(conv_5_3)\n",
        "    deconv_5_2 = Conv2DTranspose(256,kernel_size=(4, 4),strides=(2, 2), padding='valid', activation='relu')(deconv_5_1)\n",
        "    deconv_5_3 = Conv2DTranspose(128,kernel_size=(4, 4),strides=(2, 2), padding='valid', activation='relu')(deconv_5_2)\n",
        "    deconv_5_4 = Conv2DTranspose(64,kernel_size=(4, 4),strides=(2, 2), padding='valid', activation='relu')(deconv_5_3)\n",
        "    \n",
        "    attention1 = Conv2D(1, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(deconv_5_4 )\n",
        "    attention1c = Cropping2D(cropping= ((54,54),(54,54)), data_format=None)(attention1)\n",
        "    self.bn_attention1c = BatchNormalization(name='ba1c')(attention1c)\n",
        "    \n",
        "    deconv_4_1 = Conv2DTranspose(256,kernel_size=(4, 4),strides=(2, 2), padding='valid', activation='relu')(conv_4_3)\n",
        "    deconv_4_2 = Conv2DTranspose(128,kernel_size=(4, 4),strides=(2, 2), padding='valid', activation='relu')(deconv_4_1)\n",
        "    deconv_4_3 = Conv2DTranspose(64,kernel_size=(4, 4),strides=(2, 2), padding='valid', activation='relu')(deconv_4_2)\n",
        "    \n",
        "    attention2 = Conv2D(1, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(deconv_4_3 )\n",
        "    attention2c = Cropping2D(cropping= ((42,42),(42,42)))(attention2)\n",
        "    self.bn_attention2c = BatchNormalization(name='ba2c')(attention2c)\n",
        "    \n",
        "    deconv_3_1 = Conv2DTranspose(128,kernel_size=(4, 4),strides=(2, 2), padding='valid', activation='relu')(conv_3_3)\n",
        "    deconv_3_2 = Conv2DTranspose(64,kernel_size=(4, 4),strides=(2, 2), padding='valid', activation='relu')(deconv_3_1)\n",
        "    \n",
        "    attention3 = Conv2D(1, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(deconv_3_2)\n",
        "    attention3c = Cropping2D(cropping= ((36,36),(36,36)))(attention3)\n",
        "    self.bn_attention3c = BatchNormalization(name='ba3c')(attention3c)\n",
        "    \n",
        "    attention = concatenate([attention1c,attention2c,attention3c])\n",
        "    padded_attention = ZeroPadding2D(padding=(1))(attention)\n",
        "    final_attention =  Conv2D(1, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu',data_format=\"channels_last\")(padded_attention)\n",
        "    self.bn_final_attention = BatchNormalization(name='bafc')(final_attention)\n",
        "    \n",
        "    \n",
        "    self.model = Model(inputs=self.x, outputs=[self.bn_attention1c,self.bn_attention2c,self.bn_attention3c,self.bn_final_attention ])\n",
        "    \n",
        "    def custom_loss(y_true, y_pred):\n",
        "             loss1=losses.binary_crossentropy(y_true,self.bn_attention1c)\n",
        "             loss2=losses.binary_crossentropy(y_true,self.bn_attention2c)\n",
        "             loss3=losses.binary_crossentropy(y_true,self.bn_attention3c)\n",
        "             loss4=losses.binary_crossentropy(y_true,self.bn_final_attention)\n",
        "             return (loss1+loss2+loss3+loss4)/4.0\n",
        "          \n",
        "    sgd = optimizers.SGD(lr=self.lr) #Stochastic Gradient Descent Optimizer\n",
        "    self.loss = custom_loss\n",
        "    self.model.compile(optimizer = sgd , loss = self.loss, metrics=['accuracy'])\n",
        "    \n",
        "    \n",
        "    \n",
        "  def Train(self):  \n",
        "    \n",
        "    # Load data\n",
        "    X, Y= self.dataLoadBatch(self.train_no_images + self.test_no_images)\n",
        "    \n",
        "    # Train and Test split\n",
        "    X_train = X[0:self.train_no_images,:,:,:]\n",
        "    Y_train = Y[0:self.train_no_images,:,:,np.newaxis]\n",
        "    X_test =  X[self.train_no_images : self.train_no_images + self.test_no_images,  : , : , :]\n",
        "    Y_test =  Y[self.train_no_images : self.train_no_images + self.test_no_images,  : , :,np.newaxis]\n",
        "    \n",
        "    # History object stores loss and accuracy\n",
        "    hist_obj = self.model.fit(X_train, [Y_train,Y_train,Y_train,Y_train],validation_data=(X_test,[Y_test,Y_test,Y_test,Y_test]), \\\n",
        "                   batch_size=self.batch_size, epochs=self.epochs, callbacks=[TestCallback(X_train, Y_train, self.model)])       \n",
        "    output = self.model.predict(X_test)\n",
        "    self.output = np.array(output)\n",
        "    \n",
        "    # Making data global, to be used for visualization\n",
        "    self.input_image_full = X[:,:,:]\n",
        "    self.req_output_image_full =Y[:,:,:]\n",
        "    \n",
        "    return hist_obj\n",
        " \n",
        "  \n",
        "  # Prints the model architecture\n",
        "  def get_Model_Summary(self):      \n",
        "      print(self.model.summary())\n",
        "    \n",
        "\n",
        "  def Visualise_Output(self,idx): \n",
        "      self.input_image =self.input_image_full[self.train_no_images +idx,:,:]\n",
        "      self.req_output_image =self.req_output_image_full[self.train_no_images +idx,:,:]\n",
        "      pred_image_1 = self.output[0,idx,:,:,:]\n",
        "      pred_image_2 = self.output[1,idx,:,:,:]\n",
        "      pred_image_3 = self.output[2,idx,:,:,:]\n",
        "      pred_image_4 = self.output[3,idx,:,:,:]\n",
        "      fig = plt.figure(figsize=(20,10))\n",
        "      plt.subplot(231)\n",
        "      plt.imshow((self.input_image.reshape(224,224,3)), interpolation='none')\n",
        "      plt.title(\"Input - \")\n",
        "      ax = plt.gca()\n",
        "      ax.grid(False)\n",
        "      plt.subplot(232)\n",
        "      plt.imshow(self.req_output_image.reshape(224,224)*255,interpolation='none')\n",
        "      plt.title(\"Ground Truth Attention\")\n",
        "      ax = plt.gca()\n",
        "      ax.grid(False)\n",
        "      plt.subplot(233)\n",
        "      plt.imshow(pred_image_1.reshape(224,224)*255,interpolation='none')\n",
        "      plt.title(\"Predicted Attention 1 \")\n",
        "      ax = plt.gca()\n",
        "      ax.grid(False)\n",
        "      plt.subplot(234)\n",
        "      plt.imshow(pred_image_2.reshape(224,224)*255,interpolation='none')\n",
        "      plt.title(\"Predicted Attention 2 \")\n",
        "      ax = plt.gca()\n",
        "      ax.grid(False)\n",
        "      plt.subplot(235)\n",
        "      plt.imshow(pred_image_3.reshape(224,224)*255,interpolation='none')\n",
        "      plt.title(\"Predicted Attention 3 \")\n",
        "      ax = plt.gca()\n",
        "      ax.grid(False)\n",
        "      plt.subplot(236)\n",
        "      plt.imshow(pred_image_4.reshape(224,224)*255,interpolation='none')\n",
        "      plt.title(\"Predicted Final Attention \")\n",
        "      ax = plt.gca()\n",
        "      ax.grid(False)\n",
        "      plot_name = 'plot' + '_'+str(idx)+'.png'\n",
        "      print(plot_name)\n",
        "      fig.savefig(plot_name)\n",
        "    \n",
        "    \n",
        " \n",
        "  \n",
        "        \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e86PA9XoDAvg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "deconvNet = AttentionModel()\n",
        "deconvNet.DeepAttentionModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PrBTmkBDeZFS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "hist_obj = deconvNet.Train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "76QjIuAt7MFi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train_loss = hist_obj.history['loss']\n",
        "val_loss = hist_obj.history['val_loss']\n",
        "train_acc = hist_obj.history['bafc_acc']\n",
        "val_acc = hist_obj.history['val_bafc_acc']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1q3ToZIHejaR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "fig1 = plt.figure()\n",
        "plt.plot(train_loss)\n",
        "plt.plot(val_loss)\n",
        "plt.legend(['Train','Val'], loc='upper right')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.show()\n",
        "fig1.savefig('Loss.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u9Y3TcCPIhwi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "fig2 = plt.figure()\n",
        "plt.plot(train_acc)\n",
        "plt.plot(val_acc)\n",
        "plt.legend(['Train','Val'], loc='upper left')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.show()\n",
        "fig2.savefig('Accuracy.png')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z0xUTZEeOvTn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "fig3 = plt.figure()\n",
        "plt.plot(emd_arr)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('EMD')\n",
        "plt.title('Earth Movers Distance')\n",
        "plt.show()\n",
        "fig3.savefig('EMD.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-iBzDXjTCBql",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "fig4 = plt.figure()\n",
        "plt.plot(lcc_arr)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('LCC')\n",
        "plt.title('Linear Correlation Coefficient')\n",
        "plt.show()\n",
        "fig4.savefig('LCC.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_dPxEGycCgM3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "index = 1\n",
        "deconvNet.Visualise_Output(index) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6vEeg7_VMvua",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"Loss.png\" )\n",
        "files.download(\"Accuracy.png\" )\n",
        "files.download(\"EMD.png\")\n",
        "files.download(\"LCC.png\")\n",
        "files.download(\"plot_\"+str(index)+\".png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F8_LtopHJ6Y1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}