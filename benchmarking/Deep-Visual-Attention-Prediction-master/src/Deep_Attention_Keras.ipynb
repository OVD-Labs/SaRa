{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "Repg9Qqbcwem"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'mv' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'unzip' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.dropbox.com/s/ttc9hmcca04lc02/sal_data.zip?dl=0\n",
        "!mv sal_data.zip?dl=0 sal_data.zip\n",
        "!unzip sal_data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "NJqP6CLJc8US"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'mv' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'unzip' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.dropbox.com/s/0yluib4kmbhi9f4/sal_train_val.zip?dl=0\n",
        "!mv sal_train_val.zip?dl=0 sal_train_val.zip\n",
        "!unzip sal_train_val.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "naeQe-l3buEX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pydot\n",
            "  Using cached pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\user\\appdata\\roaming\\python\\python36\\site-packages (from pydot) (3.1.0)\n",
            "Installing collected packages: pydot\n",
            "Successfully installed pydot-1.4.2\n",
            "Collecting pyemd\n",
            "  Downloading pyemd-0.5.1.tar.gz (91 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.9.0 in c:\\users\\user\\anaconda3\\envs\\summer_placement\\lib\\site-packages (from pyemd) (1.19.5)\n",
            "Building wheels for collected packages: pyemd\n",
            "  Building wheel for pyemd (setup.py): started\n",
            "  Building wheel for pyemd (setup.py): finished with status 'done'\n",
            "  Created wheel for pyemd: filename=pyemd-0.5.1-cp36-cp36m-win_amd64.whl size=69200 sha256=4fee366578fd576743ccaf41a2d86d9d0359e5fc4ac49bf34384e24e4ae8a13e\n",
            "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\f9\\f0\\23\\aefbdde40e915c67830ebecb55be2344a8b6e95fe3ce3ccf96\n",
            "Successfully built pyemd\n",
            "Installing collected packages: pyemd\n",
            "Successfully installed pyemd-0.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pydot\n",
        "!pip install pyemd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "dDVgHPURBU-A"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'ls' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "JIaWWj-weHDN"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "c:\\Users\\User\\anaconda3\\envs\\summer_placement\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:493: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "c:\\Users\\User\\anaconda3\\envs\\summer_placement\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:494: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "c:\\Users\\User\\anaconda3\\envs\\summer_placement\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:495: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "c:\\Users\\User\\anaconda3\\envs\\summer_placement\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:496: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "c:\\Users\\User\\anaconda3\\envs\\summer_placement\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:497: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "c:\\Users\\User\\anaconda3\\envs\\summer_placement\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:502: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "from keras.layers import Input, Dense, Lambda, Flatten, Reshape, Concatenate,Activation\n",
        "from keras.layers import concatenate\n",
        "from keras.layers import Conv2D, Conv2DTranspose, ZeroPadding2D,MaxPooling2D, Cropping2D, BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras import metrics\n",
        "from keras import backend as K\n",
        "from keras import optimizers\n",
        "from keras import losses\n",
        "from keras.utils import plot_model\n",
        "from keras.callbacks import Callback\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "import skimage.io as io\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pydot\n",
        "from pyemd import emd, emd_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "8wRrmah6BRTf"
      },
      "outputs": [],
      "source": [
        "K.set_floatx('float32')\n",
        "emd_arr = []\n",
        "lcc_arr = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "1eL3jbehHPLo"
      },
      "outputs": [],
      "source": [
        "class TestCallback(Callback):\n",
        "    def __init__(self, X_train, Y_train, model):\n",
        "      self.X_train = X_train\n",
        "      self.Y_train = np.array(Y_train)\n",
        "      self.model = model\n",
        "\n",
        "      \n",
        "    #'Called at the end of the epoch'     \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        global emd_arr, lcc_arr\n",
        "        [y_p, y_t] = self.get_y(20)\n",
        "        emd_val = self.get_emd(y_p, y_t)\n",
        "        lcc_val = self.get_lcc(y_p, y_t)\n",
        "        print('EMD', emd_val)\n",
        "        print('LCC', lcc_val)\n",
        "        emd_arr.append(emd_val)\n",
        "        lcc_arr.append(lcc_val)\n",
        "      \n",
        "      \n",
        "    #'Returns the prediction and the true value in numpy array format'    \n",
        "    def get_y(self, index):\n",
        "        y_pred = self.model.predict(self.X_train)\n",
        "        y_pred = np.array(y_pred[3])\n",
        "        y_true = np.array(self.Y_train)\n",
        "        y_p = y_pred[index,:,:,0]\n",
        "        y_t = y_true[index,:,:,0]\n",
        "        y_p = np.ravel(y_p)\n",
        "        y_t = np.ravel(y_t)\n",
        "        return [y_p, y_t]\n",
        "      \n",
        "      \n",
        "    #'Returns the Earth Movers Distance between prediction and truth'\n",
        "    def get_emd(self,y_pred, y_true):\n",
        "      return emd_samples(y_pred, y_true)\n",
        "    \n",
        "    \n",
        "    #'Returns the Linear Correlation Coefficient between prediction and truth '\n",
        "    def get_lcc(self,y_pred, y_true):\n",
        "      return np.corrcoef(y_pred, y_true)[0,1]\n",
        "    \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "V-T1aLJleLhY"
      },
      "outputs": [],
      "source": [
        "class AttentionModel:\n",
        "  def __init__(self):\n",
        "        self.batch_size = 16\n",
        "        self.epochs = 2 #10\n",
        "        self.lr = 0.0001\n",
        "        self.train_no_images = 100#0\n",
        "        self.test_no_images = 10#0\n",
        "        \n",
        "        \n",
        "  #'Returns Data arrays with given number of samples'      \n",
        "  def dataLoadBatch(self, num_samples):\n",
        "        X=[]\n",
        "        Y=[]\n",
        "        for h in range(0, num_samples):\n",
        "            I = io.imread(\"data/images/salMap_{:05d}.jpg\".format(h))\n",
        "            X.append(I)\n",
        "            bin_label = np.zeros((224,224))\n",
        "            labels = io.imread(\"data/salMap/salMap_{:05d}.jpg\".format(h))[:,:,0]\n",
        "            for i in range(0,224):\n",
        "                for j in range(0,224):\n",
        "                  if labels[i][j]<26:\n",
        "                      bin_label[i][j] = 0\n",
        "                  elif labels[i][j]<51:\n",
        "                      bin_label[i][j] = 0.111\n",
        "                  elif labels[i][j]<76:\n",
        "                      bin_label[i][j] = 0.222\n",
        "                  elif labels[i][j]<102:\n",
        "                      bin_label[i][j] = 0.333\n",
        "                  elif labels[i][j]<128:\n",
        "                      bin_label[i][j] = 0.444\n",
        "                  elif labels[i][j]<154:\n",
        "                      bin_label[i][j] = 0.556\n",
        "                  elif labels[i][j]<180:\n",
        "                      bin_label[i][j] = 0.667\n",
        "                  elif labels[i][j]<206:\n",
        "                      bin_label[i][j] = 0.778\n",
        "                  elif labels[i][j]<230:\n",
        "                      bin_label[i][j] = 0.889                  \n",
        "                  else:\n",
        "                      bin_label[i][j] = 1\n",
        "            Y.append(bin_label)\n",
        "        X = np.array(X)\n",
        "        Y = np.array(Y)\n",
        "        \n",
        "        return X,Y\n",
        "        \n",
        "        \n",
        "  #Defines the model architecture      \n",
        "  def DeepAttentionModel(self):\n",
        "    img_rows, img_cols, img_chns = 224, 224, 3\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "      original_img_size = (img_chns, img_rows, img_cols)\n",
        "    else:\n",
        "      original_img_size = (img_rows, img_cols, img_chns)\n",
        "    \n",
        "    \n",
        "    self.x = Input(shape=original_img_size)\n",
        "    padded_x = ZeroPadding2D(padding=(35), data_format=\"channels_last\")(self.x)\n",
        "    \n",
        "    \n",
        "    #'Encoder'\n",
        "    conv_1_1 = Conv2D(64, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu',data_format=\"channels_last\")(padded_x)\n",
        "    padded_conv_1_1 = ZeroPadding2D(padding=(1), data_format=\"channels_last\")(conv_1_1)\n",
        "    conv_1_2 = Conv2D(64, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu',data_format=\"channels_last\")(padded_conv_1_1)\n",
        "    pool_1 = MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=\"channels_last\")(conv_1_2)\n",
        "    \n",
        "    padded_input_pool_1=  ZeroPadding2D(padding=(1), data_format=\"channels_last\")(pool_1)\n",
        "    conv_2_1 = Conv2D(128, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu',data_format=\"channels_last\")(padded_input_pool_1)\n",
        "    padded_input_conv_2_1 = ZeroPadding2D(padding=(1), data_format=\"channels_last\")(conv_2_1)\n",
        "    conv_2_2 = Conv2D(128, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu',data_format=\"channels_last\")(padded_input_conv_2_1)\n",
        "    pool_2 = MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=\"channels_last\")(conv_2_2)\n",
        "    \n",
        "    padded_input_pool_2=  ZeroPadding2D(padding=(1), data_format=None)(pool_2)\n",
        "    conv_3_1 = Conv2D(256, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(padded_input_pool_2)\n",
        "    padded_input_conv_3_1 = ZeroPadding2D(padding=(1), data_format=None)(conv_3_1)\n",
        "    conv_3_2 = Conv2D(256, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(padded_input_conv_3_1)\n",
        "    padded_input_conv_3_2 = ZeroPadding2D(padding=(1), data_format=None)(conv_3_2)\n",
        "    conv_3_3 = Conv2D(256, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(padded_input_conv_3_2)\n",
        "    pool_3 = MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=None)(conv_3_3)\n",
        "    \n",
        "    padded_input_pool_3 =  ZeroPadding2D(padding=(1), data_format=None)(pool_3)\n",
        "    conv_4_1 = Conv2D(512, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(padded_input_pool_3)\n",
        "    padded_input_conv_4_1 = ZeroPadding2D(padding=(1), data_format=None)(conv_4_1)\n",
        "    conv_4_2 = Conv2D(512, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(padded_input_conv_4_1)\n",
        "    padded_input_conv_4_2 = ZeroPadding2D(padding=(1), data_format=None)(conv_4_2)\n",
        "    conv_4_3 = Conv2D(512, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(padded_input_conv_4_2)\n",
        "    pool_4 = MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=None)(conv_4_3)\n",
        "    \n",
        "    padded_input_pool_4 =  ZeroPadding2D(padding=(1), data_format=None)(pool_4)\n",
        "    conv_5_1 = Conv2D(512, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(padded_input_pool_4)\n",
        "    padded_input_conv_5_1 = ZeroPadding2D(padding=(1), data_format=None)(conv_5_1)\n",
        "    conv_5_2 = Conv2D(512, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(padded_input_conv_5_1)\n",
        "    padded_input_conv_5_2 = ZeroPadding2D(padding=(1), data_format=None)(conv_5_2)\n",
        "    conv_5_3 = Conv2D(512, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(padded_input_conv_5_2)\n",
        "    \n",
        "    \n",
        "    #'Decoder'\n",
        "    deconv_5_1 = Conv2DTranspose(512,kernel_size=(4, 4),strides=(2, 2), padding='valid', activation='relu')(conv_5_3)\n",
        "    deconv_5_2 = Conv2DTranspose(256,kernel_size=(4, 4),strides=(2, 2), padding='valid', activation='relu')(deconv_5_1)\n",
        "    deconv_5_3 = Conv2DTranspose(128,kernel_size=(4, 4),strides=(2, 2), padding='valid', activation='relu')(deconv_5_2)\n",
        "    deconv_5_4 = Conv2DTranspose(64,kernel_size=(4, 4),strides=(2, 2), padding='valid', activation='relu')(deconv_5_3)\n",
        "    \n",
        "    attention1 = Conv2D(1, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(deconv_5_4 )\n",
        "    attention1c = Cropping2D(cropping= ((54,54),(54,54)), data_format=None)(attention1)\n",
        "    self.bn_attention1c = BatchNormalization(name='ba1c')(attention1c)\n",
        "    \n",
        "    deconv_4_1 = Conv2DTranspose(256,kernel_size=(4, 4),strides=(2, 2), padding='valid', activation='relu')(conv_4_3)\n",
        "    deconv_4_2 = Conv2DTranspose(128,kernel_size=(4, 4),strides=(2, 2), padding='valid', activation='relu')(deconv_4_1)\n",
        "    deconv_4_3 = Conv2DTranspose(64,kernel_size=(4, 4),strides=(2, 2), padding='valid', activation='relu')(deconv_4_2)\n",
        "    \n",
        "    attention2 = Conv2D(1, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(deconv_4_3 )\n",
        "    attention2c = Cropping2D(cropping= ((42,42),(42,42)))(attention2)\n",
        "    self.bn_attention2c = BatchNormalization(name='ba2c')(attention2c)\n",
        "    \n",
        "    deconv_3_1 = Conv2DTranspose(128,kernel_size=(4, 4),strides=(2, 2), padding='valid', activation='relu')(conv_3_3)\n",
        "    deconv_3_2 = Conv2DTranspose(64,kernel_size=(4, 4),strides=(2, 2), padding='valid', activation='relu')(deconv_3_1)\n",
        "    \n",
        "    attention3 = Conv2D(1, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(deconv_3_2)\n",
        "    attention3c = Cropping2D(cropping= ((36,36),(36,36)))(attention3)\n",
        "    self.bn_attention3c = BatchNormalization(name='ba3c')(attention3c)\n",
        "    \n",
        "    attention = concatenate([attention1c,attention2c,attention3c])\n",
        "    padded_attention = ZeroPadding2D(padding=(1))(attention)\n",
        "    final_attention =  Conv2D(1, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu',data_format=\"channels_last\")(padded_attention)\n",
        "    self.bn_final_attention = BatchNormalization(name='bafc')(final_attention)\n",
        "    \n",
        "    \n",
        "    self.model = Model(inputs=self.x, outputs=[self.bn_attention1c,self.bn_attention2c,self.bn_attention3c,self.bn_final_attention ])\n",
        "    \n",
        "    def custom_loss(y_true, y_pred):\n",
        "             loss1=losses.binary_crossentropy(y_true,self.bn_attention1c)\n",
        "             loss2=losses.binary_crossentropy(y_true,self.bn_attention2c)\n",
        "             loss3=losses.binary_crossentropy(y_true,self.bn_attention3c)\n",
        "             loss4=losses.binary_crossentropy(y_true,self.bn_final_attention)\n",
        "             return (loss1+loss2+loss3+loss4)/4.0\n",
        "          \n",
        "    sgd = optimizers.SGD(lr=self.lr) #Stochastic Gradient Descent Optimizer\n",
        "    self.loss = custom_loss\n",
        "    self.model.compile(optimizer = sgd , loss = self.loss, metrics=['accuracy'])\n",
        "    \n",
        "    \n",
        "    \n",
        "  def Train(self):  \n",
        "    \n",
        "    # Load data\n",
        "    X, Y= self.dataLoadBatch(self.train_no_images + self.test_no_images)\n",
        "    \n",
        "    # Train and Test split\n",
        "    X_train = X[0:self.train_no_images,:,:,:]\n",
        "    Y_train = Y[0:self.train_no_images,:,:,np.newaxis]\n",
        "    X_test =  X[self.train_no_images : self.train_no_images + self.test_no_images,  : , : , :]\n",
        "    Y_test =  Y[self.train_no_images : self.train_no_images + self.test_no_images,  : , :,np.newaxis]\n",
        "    \n",
        "    # History object stores loss and accuracy\n",
        "    hist_obj = self.model.fit(X_train, [Y_train,Y_train,Y_train,Y_train],validation_data=(X_test,[Y_test,Y_test,Y_test,Y_test]), \\\n",
        "                   batch_size=self.batch_size, epochs=self.epochs, callbacks=[TestCallback(X_train, Y_train, self.model)])       \n",
        "    output = self.model.predict(X_test)\n",
        "    self.output = np.array(output)\n",
        "    \n",
        "    # Making data global, to be used for visualization\n",
        "    self.input_image_full = X[:,:,:]\n",
        "    self.req_output_image_full =Y[:,:,:]\n",
        "    \n",
        "    return hist_obj\n",
        " \n",
        "  \n",
        "  # Prints the model architecture\n",
        "  def get_Model_Summary(self):      \n",
        "      print(self.model.summary())\n",
        "    \n",
        "\n",
        "  def Visualise_Output(self,idx): \n",
        "      self.input_image =self.input_image_full[self.train_no_images +idx,:,:]\n",
        "      self.req_output_image =self.req_output_image_full[self.train_no_images +idx,:,:]\n",
        "      pred_image_1 = self.output[0,idx,:,:,:]\n",
        "      pred_image_2 = self.output[1,idx,:,:,:]\n",
        "      pred_image_3 = self.output[2,idx,:,:,:]\n",
        "      pred_image_4 = self.output[3,idx,:,:,:]\n",
        "      fig = plt.figure(figsize=(20,10))\n",
        "      plt.subplot(231)\n",
        "      plt.imshow((self.input_image.reshape(224,224,3)), interpolation='none')\n",
        "      plt.title(\"Input - \")\n",
        "      ax = plt.gca()\n",
        "      ax.grid(False)\n",
        "      plt.subplot(232)\n",
        "      plt.imshow(self.req_output_image.reshape(224,224)*255,interpolation='none')\n",
        "      plt.title(\"Ground Truth Attention\")\n",
        "      ax = plt.gca()\n",
        "      ax.grid(False)\n",
        "      plt.subplot(233)\n",
        "      plt.imshow(pred_image_1.reshape(224,224)*255,interpolation='none')\n",
        "      plt.title(\"Predicted Attention 1 \")\n",
        "      ax = plt.gca()\n",
        "      ax.grid(False)\n",
        "      plt.subplot(234)\n",
        "      plt.imshow(pred_image_2.reshape(224,224)*255,interpolation='none')\n",
        "      plt.title(\"Predicted Attention 2 \")\n",
        "      ax = plt.gca()\n",
        "      ax.grid(False)\n",
        "      plt.subplot(235)\n",
        "      plt.imshow(pred_image_3.reshape(224,224)*255,interpolation='none')\n",
        "      plt.title(\"Predicted Attention 3 \")\n",
        "      ax = plt.gca()\n",
        "      ax.grid(False)\n",
        "      plt.subplot(236)\n",
        "      plt.imshow(pred_image_4.reshape(224,224)*255,interpolation='none')\n",
        "      plt.title(\"Predicted Final Attention \")\n",
        "      ax = plt.gca()\n",
        "      ax.grid(False)\n",
        "      plot_name = 'plot' + '_'+str(idx)+'.png'\n",
        "      print(plot_name)\n",
        "      fig.savefig(plot_name)\n",
        "    \n",
        "    \n",
        " \n",
        "  \n",
        "        \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "e86PA9XoDAvg"
      },
      "outputs": [],
      "source": [
        "deconvNet = AttentionModel()\n",
        "deconvNet.DeepAttentionModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "PrBTmkBDeZFS"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "No such file: 'c:\\Users\\User\\Documents\\Github\\SaRa\\benchmarking\\Deep-Visual-Attention-Prediction-master\\src\\data\\images\\salMap_00000.jpg'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-10-1e944e6043cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhist_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeconvNet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-8-cd4eab5a2b3c>\u001b[0m in \u001b[0;36mTrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[1;31m# Load data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataLoadBatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_no_images\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_no_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[1;31m# Train and Test split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-8-cd4eab5a2b3c>\u001b[0m in \u001b[0;36mdataLoadBatch\u001b[1;34m(self, num_samples)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mY\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0mI\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/images/salMap_{:05d}.jpg\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mI\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mbin_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\summer_placement\\lib\\site-packages\\skimage\\io\\_io.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'imread'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ndim'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\summer_placement\\lib\\site-packages\\skimage\\io\\manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[1;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m                                (plugin, kind))\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\summer_placement\\lib\\site-packages\\skimage\\io\\_plugins\\imageio_plugin.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\summer_placement\\lib\\site-packages\\imageio\\core\\functions.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(uri, format, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m         )\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mimopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ri\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\summer_placement\\lib\\site-packages\\imageio\\core\\imopen.py\u001b[0m in \u001b[0;36mimopen\u001b[1;34m(uri, io_mode, plugin, format_hint, legacy_mode, **kwargs)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_hint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat_hint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m         \u001b[0mrequest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mio_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat_hint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformat_hint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[0msource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"<bytes>\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\summer_placement\\lib\\site-packages\\imageio\\core\\request.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, uri, mode, format_hint, **kwargs)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[1;31m# Parse what was given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_uri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# Set extension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\summer_placement\\lib\\site-packages\\imageio\\core\\request.py\u001b[0m in \u001b[0;36m_parse_uri\u001b[1;34m(self, uri)\u001b[0m\n\u001b[0;32m    386\u001b[0m                 \u001b[1;31m# Reading: check that the file exists (but is allowed a dir)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No such file: '%s'\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m                 \u001b[1;31m# Writing: check that the directory to write to does exist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: No such file: 'c:\\Users\\User\\Documents\\Github\\SaRa\\benchmarking\\Deep-Visual-Attention-Prediction-master\\src\\data\\images\\salMap_00000.jpg'"
          ]
        }
      ],
      "source": [
        "hist_obj = deconvNet.Train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "76QjIuAt7MFi"
      },
      "outputs": [],
      "source": [
        "train_loss = hist_obj.history['loss']\n",
        "val_loss = hist_obj.history['val_loss']\n",
        "train_acc = hist_obj.history['bafc_acc']\n",
        "val_acc = hist_obj.history['val_bafc_acc']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "1q3ToZIHejaR"
      },
      "outputs": [],
      "source": [
        "fig1 = plt.figure()\n",
        "plt.plot(train_loss)\n",
        "plt.plot(val_loss)\n",
        "plt.legend(['Train','Val'], loc='upper right')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.show()\n",
        "fig1.savefig('Loss.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "u9Y3TcCPIhwi"
      },
      "outputs": [],
      "source": [
        "fig2 = plt.figure()\n",
        "plt.plot(train_acc)\n",
        "plt.plot(val_acc)\n",
        "plt.legend(['Train','Val'], loc='upper left')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.show()\n",
        "fig2.savefig('Accuracy.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "z0xUTZEeOvTn"
      },
      "outputs": [],
      "source": [
        "fig3 = plt.figure()\n",
        "plt.plot(emd_arr)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('EMD')\n",
        "plt.title('Earth Movers Distance')\n",
        "plt.show()\n",
        "fig3.savefig('EMD.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "-iBzDXjTCBql"
      },
      "outputs": [],
      "source": [
        "fig4 = plt.figure()\n",
        "plt.plot(lcc_arr)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('LCC')\n",
        "plt.title('Linear Correlation Coefficient')\n",
        "plt.show()\n",
        "fig4.savefig('LCC.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "_dPxEGycCgM3"
      },
      "outputs": [],
      "source": [
        "index = 1\n",
        "deconvNet.Visualise_Output(index) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "6vEeg7_VMvua"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-11-47dd65357196>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Loss.png\"\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy.png\"\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"EMD.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LCC.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"Loss.png\" )\n",
        "files.download(\"Accuracy.png\" )\n",
        "files.download(\"EMD.png\")\n",
        "files.download(\"LCC.png\")\n",
        "files.download(\"plot_\"+str(index)+\".png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "F8_LtopHJ6Y1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "default_view": {},
      "name": "Deep_Attention_Keras.ipynb",
      "provenance": [
        {
          "file_id": "1EURAoelzNTbdpSCCLHHzAC3eZrFaovOj",
          "timestamp": 1525544589777
        },
        {
          "file_id": "1_e7NbJ8WSGW4chf_XVdy1MihNgTUp9yg",
          "timestamp": 1525492272238
        }
      ],
      "version": "0.3.2",
      "views": {}
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
